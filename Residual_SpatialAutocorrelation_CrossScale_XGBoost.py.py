import pandas as pd
import numpy as np
import xgboost as xgb

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# PySAL ç©ºé—´ç»Ÿè®¡åº“
from libpysal.weights import KNN
from esda.moran import Moran

import warnings
warnings.filterwarnings("ignore")

# ===============================
# 1. åŸºæœ¬è®¾ç½®
# ===============================

feature_columns = [
    "SLOPE", "ELEVATION", "PD",
    "AT0", "AT10",
    "FC", "CONTAG", "FRAC",
    "SHDI", "CRDI"
]

target_column = "F"
coord_columns = ["x", "y"]

# ===============================
# 2. æŒ‡æ ‡å‡½æ•°
# ===============================

def metrics(y_true, y_pred):
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    return r2, rmse, mae


# ===============================
# 3. Spatial Block CVï¼ˆç©ºé—´åˆ†å—äº¤å‰éªŒè¯ï¼‰
# ===============================

def spatial_block_cv(df, n_blocks=5):
    """
    ç®€å•ç©ºé—´åˆ†å—CVï¼šæŒ‰Xåæ ‡åˆ†ç»„
    """
    print("\n--> æ­£åœ¨è¿›è¡Œ Spatial Block Cross-Validation...")

    df = df.copy()
    df["block"] = pd.qcut(df["x"], n_blocks, labels=False)

    block_scores = []

    for b in range(n_blocks):
        train_df = df[df["block"] != b]
        test_df  = df[df["block"] == b]

        X_train = train_df[feature_columns]
        y_train = train_df[target_column]

        X_test  = test_df[feature_columns]
        y_test  = test_df[target_column]

        model = xgb.XGBRegressor(
            n_estimators=200,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.7,
            colsample_bytree=0.7,
            objective="reg:squarederror",
            random_state=42
        )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2, rmse, mae = metrics(y_test, y_pred)
        block_scores.append(r2)

    mean_r2 = np.mean(block_scores)

    print(f"âœ… Spatial Block CV Mean RÂ² = {mean_r2:.3f}")

    return mean_r2


# ===============================
# 4. ä¸»æµç¨‹ï¼šXGBoost + Moranâ€™s I
# ===============================

def run_xgb_moran_test(file_path, scale_name):

    print("\n" + "=" * 70)
    print(f"ðŸš€ å¼€å§‹åˆ†æžå°ºåº¦: {scale_name}")
    print("=" * 70)

    # ---------- Step 1: è¯»å–æ•°æ® ----------
    df = pd.read_excel(file_path)
    print(f"æ•°æ®åŠ è½½æˆåŠŸ: {file_path}")
    print("æ ·æœ¬é‡:", df.shape[0])

    # ---------- Step 2: æå–å˜é‡ ----------
    X = df[feature_columns]
    y = df[target_column]
    coords = df[coord_columns]

    # ---------- Step 3: æ‹†åˆ†è®­ç»ƒ/æµ‹è¯• ----------
    X_train, X_test, y_train, y_test, coords_train, coords_test = train_test_split(
        X, y, coords, test_size=0.3, random_state=42
    )

    # ---------- Step 4: ç½‘æ ¼æœç´¢è¶…å‚æ•° ----------
    print("\n--> æ­£åœ¨è¿›è¡Œ XGBoost ç½‘æ ¼æœç´¢...")

    param_grid = {
        "n_estimators": [100, 200, 300],
        "max_depth": [3, 5, 7],
        "learning_rate": [0.05, 0.1, 0.2],
        "subsample": [0.7, 0.9],
        "colsample_bytree": [0.7, 0.9]
    }

    xgb_model = xgb.XGBRegressor(
        objective="reg:squarederror",
        random_state=42
    )

    grid_search = GridSearchCV(
        estimator=xgb_model,
        param_grid=param_grid,
        scoring="neg_mean_squared_error",
        cv=3,
        verbose=0,
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    best_model = grid_search.best_estimator_

    print("\nâœ… è¶…å‚æ•°æœç´¢å®Œæˆ")
    print("æœ€ä½³å‚æ•°:", grid_search.best_params_)

    # ---------- Step 5: æ¨¡åž‹æ€§èƒ½è¯„ä¼° ----------
    print("\n--> æ­£åœ¨è¯„ä¼°æ¨¡åž‹æ€§èƒ½...")

    y_train_pred = best_model.predict(X_train)
    y_test_pred  = best_model.predict(X_test)

    r2_train, rmse_train, mae_train = metrics(y_train, y_train_pred)
    r2_test, rmse_test, mae_test    = metrics(y_test, y_test_pred)

    print("\n===== XGBoost æ¨¡åž‹æ€§èƒ½ç»“æžœ =====")
    print(f"Training set: RÂ²={r2_train:.3f}, RMSE={rmse_train:.3f}, MAE={mae_train:.3f}")
    print(f"Test set:     RÂ²={r2_test:.3f}, RMSE={rmse_test:.3f}, MAE={mae_test:.3f}")

    # ---------- Overfitting æç¤º ----------
    if (r2_train - r2_test) > 0.15:
        print("âš ï¸ æç¤ºï¼šè®­ç»ƒé›†ä¸Žæµ‹è¯•é›†å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆé£Žé™©ã€‚")

    # ---------- Step 6: æ®‹å·® ----------
    residuals = y_test - y_test_pred

    # ---------- Step 7: Moranâ€™s I ----------
    print("\n--> æ­£åœ¨è¿›è¡Œ Moranâ€™s I æ®‹å·®ç©ºé—´è‡ªç›¸å…³æ£€éªŒ...")

    w = KNN.from_array(coords_test[["x", "y"]].values, k=8)
    w.transform = "R"

    # âœ… permutations=999 æ›´ä¸¥è°¨
    moran = Moran(residuals.values, w, permutations=999)

    print("\n===== Moranâ€™s I Residual Test =====")
    print("Moranâ€™s I =", round(moran.I, 4))
    print("p-value   =", round(moran.p_sim, 4))

    if moran.p_sim < 0.05:
        print("âš ï¸ æ®‹å·®å­˜åœ¨æ˜¾è‘—ç©ºé—´èšé›† â†’ è¯´æ˜Žå­˜åœ¨å°ºåº¦æ•ˆåº”æˆ–é—æ¼ç©ºé—´å˜é‡")
    else:
        print("âœ… æ®‹å·®æ— æ˜¾è‘—ç©ºé—´è‡ªç›¸å…³ â†’ é˜ˆå€¼è¯†åˆ«ç»“æžœç¨³å¥")

    # ---------- Step 8: Spatial Block CV ----------
    block_r2 = spatial_block_cv(df)

    return {
        "Scale": scale_name,
        "R2_test": r2_test,
        "RMSE_test": rmse_test,
        "MAE_test": mae_test,
        "Moran_I": moran.I,
        "p_value": moran.p_sim,
        "SpatialBlock_R2": block_r2
    }


# ===============================
# 5. åˆ†åˆ«è¿è¡Œç½‘æ ¼å°ºåº¦ä¸Žé•‡åŸŸå°ºåº¦
# ===============================

results = []

results.append(
    run_xgb_moran_test(
        r"C:\Users\4\Desktop\æ®‹å·®æ£€æŸ¥\wangge.xls",
        "Grid scale (ç½‘æ ¼)"
    )
)

results.append(
    run_xgb_moran_test(
        r"C:\Users\4\Desktop\æ®‹å·®æ£€æŸ¥\zhenyu.xls",
        "Township scale (é•‡åŸŸ)"
    )
)

# ===============================
# 6. æ±‡æ€»è¾“å‡ºï¼ˆè®ºæ–‡è¡¨æ ¼å¯ç›´æŽ¥ä½¿ç”¨ï¼‰
# ===============================

summary_df = pd.DataFrame(results)

print("\n" + "=" * 70)
print("ðŸ“Œ æœ€ç»ˆæ±‡æ€»ç»“æžœï¼ˆå¯ç›´æŽ¥å†™å…¥è®ºæ–‡ï¼‰")
print("=" * 70)
print(summary_df)

# ä¿å­˜ä¸ºExcel
summary_df.to_excel(r"C:\Users\4\Desktop\å°ºåº¦æ•ˆåº”_Moranæ±‡æ€»ç»“æžœ.xlsx", index=False)

print("\nâœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ°æ¡Œé¢: å°ºåº¦æ•ˆåº”_Moranæ±‡æ€»ç»“æžœ.xlsx")
